# Bi-Gram
Bi-Gram model to predict the next word in the sentences. 


# Word Prediction Using Bi-Gram Probable Model
Word Prediction model created with Bi-Gram Probable Model.Bigrams are used in most successful language models for speech recognition , NLP,
Crytography and Steganography. Here each word prediction has been done with the probable approach for the value of ecah predicted word.

# Context
A bigram or digram is a sequence of two adjacent elements from a string of tokens, which are typically letters, syllables, or words. A 
bigram is an n-gram for n=2. The frequency distribution of every bigram in a string is commonly used for simple statistical analysis of 
text in many applications, including in computational linguistics, cryptography, speech recognition, and so on.
Bigrams help provide the conditional probability of a token given the preceding token, when the relation of the conditional probability is 
applied

# Formulae
# p(Wn|Wn-1) = p(Wn-1, Wn) / p(Wn-1) 

That is, the probability P() of a token  Wn given the preceding token Wn-1 is equal to the probability of their bigram, or the 
co-occurrence of the two tokens  P(Wn-1,Wn) P(W_{{n-1}},W_{n}), divided by the probability of the preceding token.
